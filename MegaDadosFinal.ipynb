{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final MegaDados\n",
    "--------------\n",
    "Insper\n",
    "\n",
    "Prof. Fábio Ayres\n",
    "\n",
    "Membros: Martim F., Sabrina S., Leonardo M\n",
    "\n",
    "## Proposta Inicial\n",
    "-----\n",
    "\n",
    "O objetivo principal deste projeto foi estudar a manipulação de dados em larga escala. Qualquer quantidade de dados que não cabe na RAM pode ser considerada \"BigData\".\n",
    "Neste projeto, foi usada uma fração do web crawler de setembro (http://commoncrawl.org/) que continha apenas os sites brasileiros, com um total de apenas 65GB de 7T originais.\n",
    "\n",
    "### Tradução dos Dados em Hipóteses\n",
    "------\n",
    "Com isso, pensamos em analisar a frequência de palavras em documentos e montar um bag of words (BOW) para a totalidade dos documentos. Sequencialmente, fizemos um filtro que pegava apenas os documentos em que o nome de cada um dos 26 estado do Brasil fosse mencionado, e montamos um BOW individual para cada.\n",
    "\n",
    "Será que uma palavra (ω) é mais frequênte em textos em que \"São Paulo\" é mencionado? Por exemplo... \"Bras\"\n",
    "Será que as preposições são mencionadas igualmente no BOW total e nos BOWs filtrados? Provavelmente \"Tu\" para \"São Paulo\" terá uma frequência bem menor que do total.\n",
    "\n",
    "Assim, temos:\n",
    "\n",
    "> Hipótese 0: freq ω (estado) = freq ω (total)\n",
    "\n",
    "Em contrapartida, é possível que palavras tenham frequências totalmente divergêntes entre um estado e a visão geral dos documentos coletados:\n",
    "\n",
    "> Hipótese 1: freq ω (estado) ≠  freq ω (total)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operacionalização e Teste das Hipóteses\n",
    "--------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "#Nt = quantidade da palavra no dicionario total\n",
    "#Ne = quantidade da palavra no dicionario do estado\n",
    "#Pt = fracao da palavra/todas as palavras no dic total\n",
    "#Pe = fracao da palavra/todas as palavras no dic do estado\n",
    "def calcula_pvalue(nt, ne, pt, pe):\n",
    "    P = ((nt*pt)+(ne*pe))/(nt+ne)\n",
    "    if pe > pt:\n",
    "        Z = (pe-pt)/math.sqrt(P*(1-P)*((1/ne)+(1/nt)))\n",
    "    else:\n",
    "        Z = (pt-pe)/math.sqrt(P*(1-P)*((1/ne)+(1/nt)))\n",
    "    p_value = (1 - norm.cdf(Z))*2\n",
    "    return p_value\n",
    "\n",
    "\"\"\" Passos do nosso projeto:\n",
    "* Para cada estado, ordenar a lista de tupla pela palavra com maior frequência\n",
    "* Pegar as 20 palavras mais faladas de cada estado\n",
    "\n",
    "* Para construir o bag of word geral (todos os estados):\n",
    "** Criar lista geral com todas as palavras d \n",
    "\"\"\"\n",
    "\n",
    "def get_total(dic_label):\n",
    "    total = 0\n",
    "    for tupla in dic_label:\n",
    "        total += tupla[1]\n",
    "    return total\n",
    "\n",
    "def get_quantidade_palavra_total(palavra, list_total):\n",
    "    for indice, tupla in enumerate(list_total):\n",
    "        if tupla[0] == palavra:\n",
    "            return list_total[indice][1]\n",
    "\n",
    "def get_fracao_palavra(tupla, total):\n",
    "    return tupla[1]/total\n",
    "\n",
    "def save(data, name):\n",
    "    with open(name, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                ## MAIN ##\n",
    "## Rodar apenas quando for gerar o pickle ##\n",
    "\n",
    "with open('frequencia_palavras2.pickle', 'rb') as handle:\n",
    "    dic_load = pickle.load(handle)\n",
    "\n",
    "with open('frequencia_palavras_geral2.pickle', 'rb') as handle:\n",
    "    dic_geral_load = pickle.load(handle)\n",
    "\n",
    "total = get_total(dic_geral_load)\n",
    "dic_final = {}\n",
    "\n",
    "for key, lista_tupla in dic_load.items():\n",
    "\n",
    "    dic_final[key] = [] \n",
    "    total_capital  = get_total(dic_load[key]) \n",
    "\n",
    "    for tupla in lista_tupla:\n",
    "            palavra = tupla[0]\n",
    "            Ne      = tupla[1] \n",
    "            Nt      = get_quantidade_palavra_total(palavra, dic_geral_load) \n",
    "            Pt      = get_fracao_palavra(tupla, total)\n",
    "            Pe      = get_fracao_palavra(tupla, total_capital)\n",
    "            pvalue  = calcula_pvalue(Nt, Ne, Pt, Pe)\n",
    "            dic_final[key].append((palavra, Pt, Pe, pvalue))\n",
    "\n",
    "save(dic_final, \"palavras_pvalue.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pprint\n",
    "\n",
    "with open('palavras_pvalue.pickle', 'rb') as handle:\n",
    "    dic_pvalue = pickle.load(handle)\n",
    "\n",
    "dic = sorted(dic_pvalue[\"São Paulo\"], key=lambda x: x[3], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'palavra' : [dic[0] for n in dic],\n",
    "    'P_total' : [dic[1] for n in dic],\n",
    "    'P_estado': [dic[2] for n in dic],\n",
    "    'P-value' : [dic[3] for n in dic],\n",
    "    })\n",
    "data.set_index('palavra')\n",
    "\n",
    "\n",
    "\n",
    "for element in dic_final:\n",
    "    key = dic_final[element]\n",
    "    dt = pd.DataFrame({   \n",
    "        'palavra' : [key[n][0] for n in range(len(key))],\n",
    "        'P_total' : [key[n][1] for n in range(len(key))],\n",
    "        'P_estado': [key[n][2] for n in range(len(key))],\n",
    "        'P-value' : [key[n][3] for n in range(len(key))],\n",
    "        })\n",
    "\n",
    "dt.set_index('palavra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
